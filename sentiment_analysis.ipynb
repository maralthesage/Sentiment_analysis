{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas scikit_learn surprise\n",
    "# !pip install openpyxl\n",
    "# !pip install transformers\n",
    "# !pip install matplotlib seaborn\n",
    "# !pip install wordcloud\n",
    "# !pip install tensorflow\n",
    "# !pip install tf-keras\n",
    "# !pip install nltk\n",
    "# !pip install pyarrow\n",
    "# !pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('/Users/maralsheikhzadeh/Documents/Codes/Server-Connect/etrusted_reviews_2024-07-17_09-31.xlsx')\n",
    "df = pd.read_parquet('Exports/sentiment_analysis.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the needed columns\n",
    "df = df[['Bewertungs-ID',\n",
    " 'Erstellt-Datum',\n",
    " 'E-Mail',\n",
    " 'Bewertung',\n",
    " 'Bewertungstitel',\n",
    " 'Bewertungstext',\n",
    " 'Beantwortet-Datum',\n",
    " 'Antworttext',\n",
    " 'Referenz',\n",
    " 'Vorlage',\n",
    " 'Produkt-ID',\n",
    " 'Produkt-SKU',\n",
    " 'Produktname',\n",
    " 'Produkt-URL',\n",
    " 'Produktbild-URL',\n",
    " 'sentiment']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Positive, Neutral and Negativ reviews for each Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Custom aggregation function to count each sentiment separately\n",
    "# def count_sentiments(sentiments):\n",
    "#     sentiment_counts = sentiments.value_counts()\n",
    "#     positive = sentiment_counts.get('POSITIVE', 0)\n",
    "#     neutral = sentiment_counts.get('NEUTRAL', 0)\n",
    "#     negative = sentiment_counts.get('NEGATIVE', 0)\n",
    "#     return pd.Series({'POSITIVE': positive, 'NEUTRAL': neutral, 'NEGATIVE': negative})\n",
    "\n",
    "# # Group by 'Produkt-SKU' and apply the custom aggregation function\n",
    "# average_review = df.groupby('Produkt-SKU').agg(\n",
    "#     Bewertungstext=('Bewertungstext', ' *** '.join),\n",
    "#     Positive_Count=('sentiment_mapped', lambda x: count_sentiments(x)['POSITIVE']),\n",
    "#     Neutral_Count=('sentiment_mapped', lambda x: count_sentiments(x)['NEUTRAL']),\n",
    "#     Negative_Count=('sentiment_mapped', lambda x: count_sentiments(x)['NEGATIVE'])\n",
    "# ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# average_review.to_csv('average_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Sentiment analysis model (Takes a while to process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Applying Sentiment analysis model to the data\n",
    "# sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "# df['sentiment'] = df['cleaned_reviews'].apply(lambda x: sentiment_pipeline(x)[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming/Mapping sentiment results to POSITIVE,NEUTRAL and NEGATIVE values\n",
    "label_mapping = {\n",
    "    '1 star': 'NEGATIVE',\n",
    "    '2 stars': 'NEGATIVE',\n",
    "    '3 stars': 'NEUTRAL',\n",
    "    '4 stars': 'POSITIVE',\n",
    "    '5 stars': 'POSITIVE'\n",
    "}\n",
    "\n",
    "df['sentiment_mapped'] = df['sentiment'].map(label_mapping)\n",
    "\n",
    "## Saving the df to Parquet format\n",
    "# df.to_parquet('sentiment_analysis.parquet',index=False)\n",
    "\n",
    "## Formatting the Date column as date type\n",
    "df['Erstellt-Datum'] = pd.to_datetime(df['Erstellt-Datum'], format='%d.%m.%y, %H:%M')\n",
    "df['Erstellt-Datum'] = df['Erstellt-Datum'].dt.strftime('%Y-%m-%d')\n",
    "# df.set_index('Erstellt-Datum',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data to a Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['Erstellt-Datum','Produkt-SKU', 'Bewertungstext','sentiment_mapped']]\n",
    "\n",
    "def aggregate_reviews(texts):\n",
    "    unique_texts = list(set(texts))\n",
    "    return ' *** '.join(unique_texts)\n",
    "\n",
    "# Create the pivot table\n",
    "pivot_df = new_df.pivot_table(index=['Erstellt-Datum', 'Produkt-SKU'], \n",
    "                          columns='sentiment_mapped', \n",
    "                          values='Bewertungstext', \n",
    "                          aggfunc=aggregate_reviews, \n",
    "                          fill_value='')\n",
    "\n",
    "# Reset the index to flatten the DataFrame\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "pivot_df.columns.name = None\n",
    "pivot_df = pivot_df[pivot_df['Produkt-SKU'].str.endswith('P')==False]\n",
    "pivot_df.to_excel('Exports/pivot_reviews.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Most frequent Phrases from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the German language model\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def extract_noun_verb_phrases(text):\n",
    "    doc = nlp(text)\n",
    "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    verb_groups = [token.text for token in doc if token.pos_ == 'VERB']\n",
    "    return noun_phrases + verb_groups  # Concatenate noun_phrases and verb_groups into a single list\n",
    "\n",
    "# Apply the function to each row in the 'Bewertungstext' column\n",
    "df['Noun_Phrases'] = df['Bewertungstext'].str.lower()\n",
    "df['Noun_Phrases'] = df['Noun_Phrases'].apply(extract_noun_verb_phrases)\n",
    "\n",
    "# Handling NaN values\n",
    "df['Noun_Phrases'] = df['Noun_Phrases'].fillna('0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Most Frequent Phrases in Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the text into words (tokenization)\n",
    "texts = df['Noun_Phrases']\n",
    "\n",
    "\n",
    "# Step 2: Filter out empty lists\n",
    "new = texts[texts.apply(lambda x: isinstance(x, list) and len(x) > 0)].values.tolist()\n",
    "\n",
    "\n",
    "# Step 3: Flatten the list of lists\n",
    "corpus = [word for sublist in new for word in sublist]\n",
    "\n",
    "\n",
    "# Step 4: Count the words\n",
    "counter = Counter(corpus)\n",
    "most = counter.most_common()\n",
    "\n",
    "\n",
    "# Step 5: Prepare the data for plotting\n",
    "x, y = [], []\n",
    "german_stop_words = [\n",
    "    \"aber\", \"als\", \"am\", \"an\", \"auf\", \"aus\", \"bei\", \"bin\", \"bis\", \"da\", \"durch\", \n",
    "    \"ein\", \"eine\", \"einer\", \"eines\", \"einem\", \"einen\", \"es\", \"für\", \"gegen\", \n",
    "    \"habe\", \"haben\", \"hat\", \"hatte\", \"hier\", \"ich\", \"in\", \"ist\", \"ja\", \"jedoch\", \n",
    "    \"kann\", \"könnte\", \"machen\", \"mein\", \"meine\", \"mit\", \"nach\", \"nicht\", \"nur\", \n",
    "    \"oder\", \"sein\", \"seine\", \"sind\", \"so\", \"über\", \"um\", \"und\", \"unser\", \"unsere\", \n",
    "    \"von\", \"vor\", \"was\", \"weil\", \"wie\", \"will\", \"wir\", \"wird\", \"wo\", \"zu\", \"zum\", \n",
    "    \"zur\",'-','##e','.','!','Ich','war','sehr','alles','allem','der','die','das'\n",
    "]\n",
    "\n",
    "for word, count in most[:300]:\n",
    "    if word not in german_stop_words:\n",
    "        ## We only want two or longer phrases that are descriptive (hence with no articles)\n",
    "        if (len(word.split()) > 1) and (word.split()[0] not in ['der', 'die', 'das']):\n",
    "            print(word)\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "\n",
    "# Step 6: Create the bar plot\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=y,\n",
    "    y=x,\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='rgba(50, 171, 96, 0.6)',\n",
    "        line=dict(\n",
    "            color='rgba(50, 171, 96, 1.0)',\n",
    "            width=1\n",
    "        )\n",
    "    ),\n",
    "    name='Most common Word'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Most Common Words\",\n",
    "        'y': 0.9,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=11,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Average Rating and number of rating for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_sorted = df.groupby(['Produkt-SKU', 'Produktname']).agg(\n",
    "    Durchschnitt_Bewertungen=('Bewertung', 'mean'),\n",
    "    Anzahl_Bewertungen=('Bewertung', 'count')\n",
    ").sort_values('Anzahl_Bewertungen', ascending=False).reset_index()\n",
    "\n",
    "rating_sorted.to_csv('Exports/all_product_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top and Flop rated Products based on both the Average rating and the number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_sorted = rating_sorted[rating_sorted['sentiment_mapped']]\n",
    "rating_sorted['rating'] = rating_sorted['Durchschnitt_Bewertungen'] * rating_sorted['Anzahl_Bewertungen']\n",
    "top_rated = rating_sorted.sort_values('rating',ascending=False)[:100]\n",
    "# top_rated = top_rated.rename(columns={'Produkt-SKU':'NUMMER','Bewertung':'Bewertung (Durschnitt)','sentiment_mapped':'Anzahl die Bewertungen'})\n",
    "top_rated = top_rated[['Produkt-SKU','Produktname','Durchschnitt_Bewertungen','Anzahl_Bewertungen']]\n",
    "top_rated.to_csv('Exports/top_rated_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_sorted = rating_sorted[rating_sorted['sentiment_mapped']]\n",
    "# rating_sorted['rating'] = rating_sorted['Bewertung'] * rating_sorted['sentiment_mapped']\n",
    "flop_rated = rating_sorted.sort_values(['Durchschnitt_Bewertungen','Anzahl_Bewertungen'],ascending=[True,True])\n",
    "flop_rated = flop_rated[(flop_rated['Anzahl_Bewertungen']>=2)& (flop_rated['Durchschnitt_Bewertungen'] <= 3)][:100]\n",
    "# flop_rated = flop_rated.rename(columns={'Produkt-SKU':'NUMMER','Bewertung':'Bewertung (Durschnitt)','sentiment_mapped':'Anzahl die Bewertungen'})\n",
    "flop_rated = flop_rated[['Produkt-SKU','Produktname','Durchschnitt_Bewertungen','Anzahl_Bewertungen']]\n",
    "flop_rated.to_csv('Exports/flop_rated_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_summary = df.groupby('Produkt-SKU')['sentiment_mapped'].value_counts().unstack().fillna(0)\n",
    "sentiment_summary.sort_values(by='POSITIVE',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_summary.plot(kind='bar', stacked=True)\n",
    "# plt.title('Sentiment Distribution by Product')\n",
    "# plt.xlabel('Product ID')\n",
    "# plt.ylabel('Number of Reviews')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean text and remove stopwords\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Ensure the text is a string\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word.lower() not in german_stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    return ''  # Return an empty string if not a valid string\n",
    "\n",
    "# Clean the reviews to remove stopwords\n",
    "positive_reviews = ' '.join(df[df['sentiment_mapped'] == 'POSITIVE']['Bewertungstext'].dropna().astype(str))\n",
    "negative_reviews = ' '.join(df[df['sentiment_mapped'] == 'NEGATIVE']['Bewertungstext'].dropna().astype(str))\n",
    "\n",
    "# Clean the concatenated reviews\n",
    "cleaned_positive_reviews = clean_text(positive_reviews)\n",
    "cleaned_negative_reviews = clean_text(negative_reviews)\n",
    "\n",
    "# Generate word clouds with cleaned text\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(cleaned_positive_reviews)\n",
    "wordcloud_neg = WordCloud(width=800, height=400, background_color='white').generate(cleaned_negative_reviews)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_pos, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Positive Reviews Word Cloud')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_neg, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Negative Reviews Word Cloud')\n",
    "\n",
    "plt.tight_layout()  # Ensures plots are neatly arranged\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
